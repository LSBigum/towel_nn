{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "for i in range(50):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laus/.virtualenvs/virtual-py3/lib/python3.5/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 1s - loss: 0.6539 - acc: 0.5581\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6119 - acc: 0.6371\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.5692 - acc: 0.7100\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5297 - acc: 0.7557\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.4907 - acc: 0.7890\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.4510 - acc: 0.8300\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4135 - acc: 0.8571\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.3790 - acc: 0.8771\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.3465 - acc: 0.8933\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.3170 - acc: 0.9029\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.2934 - acc: 0.9157\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2744 - acc: 0.9200\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2583 - acc: 0.9238\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2450 - acc: 0.9290\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2341 - acc: 0.9329\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2248 - acc: 0.9371\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2171 - acc: 0.9386\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2104 - acc: 0.9405\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2042 - acc: 0.9410\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.1989 - acc: 0.9433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce54834400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13,64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laus/.virtualenvs/virtual-py3/lib/python3.5/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8582236  0.14177637]\n",
      "[0.16881827 0.83118176]\n",
      "[0.5608807  0.43911928]\n",
      "[0.01723693 0.98276305]\n",
      "[0.6612943  0.33870572]\n",
      "[0.21229625 0.78770375]\n",
      "[0.8892891  0.11071087]\n",
      "[0.3534468  0.64655316]\n",
      "[0.4204233  0.57957673]\n",
      "[0.09102012 0.9089799 ]\n",
      "[0.9517287  0.04827134]\n",
      "[0.14988932 0.85011065]\n",
      "[0.95803434 0.04196569]\n",
      "[0.06148111 0.93851894]\n",
      "[0.9603262  0.03967381]\n",
      "[0.01912142 0.9808786 ]\n",
      "[0.9596236  0.04037646]\n",
      "[0.01723693 0.98276305]\n",
      "[0.87457794 0.12542202]\n",
      "[0.32183185 0.6781682 ]\n",
      "[0.9590632  0.04093686]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.38639775 0.6136023 ]\n",
      "[0.05380839 0.94619155]\n",
      "[0.93333006 0.06666991]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.9603262  0.03967381]\n",
      "[0.3534468  0.64655316]\n",
      "[0.9560482  0.04395176]\n",
      "[0.02149443 0.9785056 ]\n",
      "[0.9273371  0.07266292]\n",
      "[0.07016686 0.9298332 ]\n",
      "[0.95803434 0.04196569]\n",
      "[0.23690988 0.7630901 ]\n",
      "[0.95705223 0.04294776]\n",
      "[0.0411384  0.95886153]\n",
      "[0.9596236  0.04037646]\n",
      "[0.0121284 0.9878715]\n",
      "[0.9596236  0.04037646]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.5608807  0.43911928]\n",
      "[0.02149443 0.9785056 ]\n",
      "[0.92012745 0.07987255]\n",
      "[0.01112093 0.9888791 ]\n",
      "[0.6612943  0.33870572]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.95672    0.04327997]\n",
      "[0.18960439 0.8103956 ]\n",
      "[0.9612138  0.03878616]\n",
      "[0.07997505 0.92002493]\n",
      "[0.95803434 0.04196569]\n",
      "[0.01019627 0.9898037 ]\n",
      "[0.9590632  0.04093686]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.9577094  0.04229064]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.6612943  0.33870572]\n",
      "[0.3534468  0.64655316]\n",
      "[0.95931035 0.04068962]\n",
      "[0.01019627 0.9898037 ]\n",
      "[0.911955   0.08804498]\n",
      "[0.32183185 0.6781682 ]\n",
      "[0.4904638 0.5095362]\n",
      "[0.05380839 0.94619155]\n",
      "[0.96054924 0.03945076]\n",
      "[0.00856927 0.9914307 ]\n",
      "[0.9612138  0.03878616]\n",
      "[0.01723693 0.98276305]\n",
      "[0.8892891  0.11071087]\n",
      "[0.0121284 0.9878715]\n",
      "[0.9577094  0.04229064]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.9273371  0.07266292]\n",
      "[0.16881827 0.83118176]\n",
      "[0.5608807  0.43911928]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.87457794 0.12542202]\n",
      "[0.00934777 0.9906522 ]\n",
      "[0.95502585 0.04497414]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.4204233  0.57957673]\n",
      "[0.10341913 0.8965809 ]\n",
      "[0.74902093 0.25097913]\n",
      "[0.3534468  0.64655316]\n",
      "[0.9608532  0.03914674]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.4204233  0.57957673]\n",
      "[0.16881827 0.83118176]\n",
      "[0.9517287  0.04827134]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.74902093 0.25097913]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.93870914 0.06129083]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.95705223 0.04294776]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.95835686 0.04164312]\n",
      "[0.07997505 0.92002493]\n",
      "[0.9273371  0.07266292]\n",
      "[0.07016686 0.9298332 ]\n",
      "[0.8892891  0.11071087]\n",
      "[0.07016686 0.9298332 ]\n",
      "[0.9436804  0.05631959]\n",
      "[0.01112093 0.9888791 ]\n",
      "[0.95672    0.04327997]\n",
      "[0.14988932 0.85011065]\n",
      "[0.9599345  0.04006561]\n",
      "[0.23690988 0.7630901 ]\n",
      "[0.84012663 0.1598734 ]\n",
      "[0.0411384  0.95886153]\n",
      "[0.95931035 0.04068962]\n",
      "[0.05380839 0.94619155]\n",
      "[0.7983934  0.20160654]\n",
      "[0.07997505 0.92002493]\n",
      "[0.84012663 0.1598734 ]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.9608532  0.03914674]\n",
      "[0.05380839 0.94619155]\n",
      "[0.911955   0.08804498]\n",
      "[0.09102012 0.9089799 ]\n",
      "[0.95835686 0.04164312]\n",
      "[0.14988932 0.85011065]\n",
      "[0.82020354 0.17979649]\n",
      "[0.01912142 0.9808786 ]\n",
      "[0.95899487 0.04100511]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.82020354 0.17979649]\n",
      "[0.00719999 0.9928    ]\n",
      "[0.69221824 0.30778173]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.87457794 0.12542202]\n",
      "[0.05380839 0.94619155]\n",
      "[0.77466464 0.22533534]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.82020354 0.17979649]\n",
      "[0.01322594 0.9867741 ]\n",
      "[0.82020354 0.17979649]\n",
      "[0.01019627 0.9898037 ]\n",
      "[0.4904638 0.5095362]\n",
      "[0.16881827 0.83118176]\n",
      "[0.9563854  0.04361462]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.74902093 0.25097913]\n",
      "[0.21229625 0.78770375]\n",
      "[0.77466464 0.22533534]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.9608532  0.03914674]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.95502585 0.04497414]\n",
      "[0.07997505 0.92002493]\n",
      "[0.7983934  0.20160654]\n",
      "[0.01112093 0.9888791 ]\n",
      "[0.9612138  0.03878616]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.95803434 0.04196569]\n",
      "[0.01322594 0.9867741 ]\n",
      "[0.9599345  0.04006561]\n",
      "[0.11728909 0.8827109 ]\n",
      "[0.9553665  0.04463349]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.59536296 0.4046371 ]\n",
      "[0.05380839 0.94619155]\n",
      "[0.9560482  0.04395176]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.82020354 0.17979649]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.96115124 0.03884877]\n",
      "[0.01019627 0.9898037 ]\n",
      "[0.9479104 0.0520896]\n",
      "[0.32183185 0.6781682 ]\n",
      "[0.93870914 0.06129083]\n",
      "[0.11728909 0.8827109 ]\n",
      "[0.7983934  0.20160654]\n",
      "[0.07997505 0.92002493]\n",
      "[0.74902093 0.25097913]\n",
      "[0.00856927 0.9914307 ]\n",
      "[0.4904638 0.5095362]\n",
      "[0.07016686 0.9298332 ]\n",
      "[0.84012663 0.1598734 ]\n",
      "[0.05380839 0.94619155]\n",
      "[0.95672    0.04327997]\n",
      "[0.18960439 0.8103956 ]\n",
      "[0.87457794 0.12542202]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.96115124 0.03884877]\n",
      "[0.14988932 0.85011065]\n",
      "[0.92012745 0.07987255]\n",
      "[0.0121284 0.9878715]\n",
      "[0.9517287  0.04827134]\n",
      "[0.07997505 0.92002493]\n",
      "[0.9563854  0.04361462]\n",
      "[0.23690988 0.7630901 ]\n",
      "[0.9019048 0.0980951]\n",
      "[0.01912142 0.9808786 ]\n",
      "[0.9563854  0.04361462]\n",
      "[0.09102012 0.9089799 ]\n",
      "[0.95803434 0.04196569]\n",
      "[0.3534468  0.64655316]\n",
      "[0.9563854  0.04361462]\n",
      "[0.16881827 0.83118176]\n",
      "[0.8892891  0.11071087]\n",
      "[0.00719999 0.9928    ]\n",
      "[0.82020354 0.17979649]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.957382   0.04261799]\n",
      "[0.32183185 0.6781682 ]\n",
      "[0.9603262  0.03967381]\n",
      "[0.13274394 0.86725605]\n",
      "[0.62892866 0.37107128]\n",
      "[0.10341913 0.8965809 ]\n",
      "[0.59536296 0.4046371 ]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.960243   0.03975704]\n",
      "[0.11728909 0.8827109 ]\n",
      "[0.9599345  0.04006561]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.5258006  0.47419938]\n",
      "[0.14988932 0.85011065]\n",
      "[0.96054924 0.03945076]\n",
      "[0.01723693 0.98276305]\n",
      "[0.9553665  0.04463349]\n",
      "[0.14988932 0.85011065]\n",
      "[0.957382   0.04261799]\n",
      "[0.3534468  0.64655316]\n",
      "[0.9557086  0.04429136]\n",
      "[0.01112093 0.9888791 ]\n",
      "[0.9603262  0.03967381]\n",
      "[0.0411384  0.95886153]\n",
      "[0.9563854  0.04361462]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.9590632  0.04093686]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.95502585 0.04497414]\n",
      "[0.09102012 0.9089799 ]\n",
      "[0.4204233  0.57957673]\n",
      "[0.263423   0.73657703]\n",
      "[0.957382   0.04261799]\n",
      "[0.06148111 0.93851894]\n",
      "[0.8892891  0.11071087]\n",
      "[0.01019627 0.9898037 ]\n",
      "[0.9596236  0.04037646]\n",
      "[0.21229625 0.78770375]\n",
      "[0.9560482  0.04395176]\n",
      "[0.01723693 0.98276305]\n",
      "[0.9517287  0.04827134]\n",
      "[0.18960439 0.8103956 ]\n",
      "[0.9517287  0.04827134]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.93333006 0.06666991]\n",
      "[0.01723693 0.98276305]\n",
      "[0.96054924 0.03945076]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.9577094  0.04229064]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.95899487 0.04100511]\n",
      "[0.00719999 0.9928    ]\n",
      "[0.911955   0.08804498]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.95835686 0.04164312]\n",
      "[0.05380839 0.94619155]\n",
      "[0.9019048 0.0980951]\n",
      "[0.09102012 0.9089799 ]\n",
      "[0.95803434 0.04196569]\n",
      "[0.13274394 0.86725605]\n",
      "[0.9563854  0.04361462]\n",
      "[0.0411384  0.95886153]\n",
      "[0.95931035 0.04068962]\n",
      "[0.06148111 0.93851894]\n",
      "[0.911955   0.08804498]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.45522204 0.544778  ]\n",
      "[0.07016686 0.9298332 ]\n",
      "[0.95803434 0.04196569]\n",
      "[0.01723693 0.98276305]\n",
      "[0.9563854  0.04361462]\n",
      "[0.00934777 0.9906522 ]\n",
      "[0.8582236  0.14177637]\n",
      "[0.3534468  0.64655316]\n",
      "[0.8582236  0.14177637]\n",
      "[0.05380839 0.94619155]\n",
      "[0.9563854  0.04361462]\n",
      "[0.05380839 0.94619155]\n",
      "[0.96115124 0.03884877]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.38639775 0.6136023 ]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.92012745 0.07987255]\n",
      "[0.06148111 0.93851894]\n",
      "[0.95803434 0.04196569]\n",
      "[0.06148111 0.93851894]\n",
      "[0.4904638 0.5095362]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.95502585 0.04497414]\n",
      "[0.01322594 0.9867741 ]\n",
      "[0.9590632  0.04093686]\n",
      "[0.21229625 0.78770375]\n",
      "[0.59536296 0.4046371 ]\n",
      "[0.16881827 0.83118176]\n",
      "[0.95502585 0.04497414]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.93870914 0.06129083]\n",
      "[0.0121284 0.9878715]\n",
      "[0.59536296 0.4046371 ]\n",
      "[0.02433764 0.9756623 ]\n",
      "[0.9019048 0.0980951]\n",
      "[0.06148111 0.93851894]\n",
      "[0.72150797 0.2784921 ]\n",
      "[0.3534468  0.64655316]\n",
      "[0.95931035 0.04068962]\n",
      "[0.00856927 0.9914307 ]\n",
      "[0.74902093 0.25097913]\n",
      "[0.11728909 0.8827109 ]\n",
      "[0.93333006 0.06666991]\n",
      "[0.11728909 0.8827109 ]\n",
      "[0.9596236  0.04037646]\n",
      "[0.29176873 0.7082312 ]\n",
      "[0.9577094  0.04229064]\n",
      "[0.03160332 0.9683966 ]\n",
      "[0.95803434 0.04196569]\n",
      "[0.00856927 0.9914307 ]\n",
      "[0.38639775 0.6136023 ]\n",
      "[0.00934777 0.9906522 ]\n",
      "[0.95705223 0.04294776]\n",
      "[0.07997505 0.92002493]\n",
      "[0.93333006 0.06666991]\n",
      "[0.05380839 0.94619155]\n",
      "[0.95803434 0.04196569]\n",
      "[0.32183185 0.6781682 ]\n",
      "[0.59536296 0.4046371 ]\n",
      "[0.01442134 0.98557866]\n",
      "[0.958677   0.04132294]\n",
      "[0.0411384  0.95886153]\n",
      "[0.9553665  0.04463349]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.38639775 0.6136023 ]\n",
      "[0.02149443 0.9785056 ]\n",
      "[0.9517287  0.04827134]\n",
      "[0.07997505 0.92002493]\n",
      "[0.95757073 0.0424292 ]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.69221824 0.30778173]\n",
      "[0.0121284 0.9878715]\n",
      "[0.6612943  0.33870572]\n",
      "[0.13274394 0.86725605]\n",
      "[0.9563854  0.04361462]\n",
      "[0.01442134 0.98557866]\n",
      "[0.38639775 0.6136023 ]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.960243   0.03975704]\n",
      "[0.05380839 0.94619155]\n",
      "[0.958677   0.04132294]\n",
      "[0.06148111 0.93851894]\n",
      "[0.6612943  0.33870572]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.72150797 0.2784921 ]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.95835686 0.04164312]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.9577094  0.04229064]\n",
      "[0.07016686 0.9298332 ]\n",
      "[0.95705223 0.04294776]\n",
      "[0.09102012 0.9089799 ]\n",
      "[0.8582236  0.14177637]\n",
      "[0.29176873 0.7082312 ]\n",
      "[0.96054924 0.03945076]\n",
      "[0.0121284 0.9878715]\n",
      "[0.96115124 0.03884877]\n",
      "[0.3534468  0.64655316]\n",
      "[0.9553665  0.04463349]\n",
      "[0.14988932 0.85011065]\n",
      "[0.6612943  0.33870572]\n",
      "[0.13274394 0.86725605]\n",
      "[0.59536296 0.4046371 ]\n",
      "[0.29176873 0.7082312 ]\n",
      "[0.9596236  0.04037646]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.8892891  0.11071087]\n",
      "[0.11728909 0.8827109 ]\n",
      "[0.69221824 0.30778173]\n",
      "[0.10341913 0.8965809 ]\n",
      "[0.38639775 0.6136023 ]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.9557086  0.04429136]\n",
      "[0.07997505 0.92002493]\n",
      "[0.77466464 0.22533534]\n",
      "[0.01572306 0.9842769 ]\n",
      "[0.95931035 0.04068962]\n",
      "[0.05380839 0.94619155]\n",
      "[0.8892891  0.11071087]\n",
      "[0.263423   0.73657703]\n",
      "[0.4904638 0.5095362]\n",
      "[0.04704516 0.9529548 ]\n",
      "[0.9553665  0.04463349]\n",
      "[0.00856927 0.9914307 ]\n",
      "[0.9596236  0.04037646]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.9517287  0.04827134]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.96115124 0.03884877]\n",
      "[0.03606879 0.96393114]\n",
      "[0.95757073 0.0424292 ]\n",
      "[0.02767785 0.9723221 ]\n",
      "[0.82020354 0.17979649]\n",
      "[0.06148111 0.93851894]\n",
      "[0.59536296 0.4046371 ]\n",
      "[0.07016686 0.9298332 ]\n",
      "[0.77466464 0.22533534]\n",
      "[0.07997505 0.92002493]\n",
      "[0.96115124 0.03884877]\n",
      "[0.01322594 0.9867741 ]\n",
      "[0.9557086  0.04429136]\n",
      "[0.3534468  0.64655316]\n",
      "[0.62892866 0.37107128]\n",
      "[0.14988932 0.85011065]\n",
      "[0.87457794 0.12542202]\n",
      "[0.00785509 0.9921449 ]\n",
      "[0.9560482  0.04395176]\n",
      "[0.13274394 0.86725605]\n",
      "[0.9517287  0.04827134]\n",
      "[0.29176873 0.7082312 ]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(cm,annot=True,fmt='.5g', ax = ax) \n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save functions saves:\n",
    "- The architecture of the model, allowing to re-create the model.\n",
    "- The weights of the model.\n",
    "- The training configuration (loss, optimizer).\n",
    "- The state of the optimizer, allowing to resume training exactly where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.36052594, -0.5693807 ,  0.55063176,  0.7302026 ,  0.6128825 ,\n",
       "          0.25918075,  0.44889954, -0.0070352 , -0.36083278,  0.35058415,\n",
       "         -0.15377635, -0.13135599,  0.16218145,  0.6635311 ,  0.4402842 ,\n",
       "         -0.02408093]], dtype=float32),\n",
       " array([ 0.03780906,  0.        , -0.13851134, -0.15858932, -0.12663199,\n",
       "        -0.09662379, -0.11594727,  0.        ,  0.        , -0.12754516,\n",
       "         0.        ,  0.17744114,  0.19280577,  0.17318337, -0.11936235,\n",
       "         0.        ], dtype=float32),\n",
       " array([[ 3.71231228e-01, -5.36492653e-02, -2.13835895e-01,\n",
       "         -1.06769085e-01, -8.28440189e-02,  1.38934821e-01,\n",
       "         -2.24269956e-01,  1.84396610e-01,  1.05756804e-01,\n",
       "         -3.02074552e-01,  2.38338336e-01,  3.64449285e-02,\n",
       "          1.70295388e-01, -4.16639857e-02,  1.87481850e-01,\n",
       "         -2.57548779e-01,  2.85643667e-01,  2.95934737e-01,\n",
       "          1.11540608e-01, -2.42348582e-01, -3.43800008e-01,\n",
       "         -9.95157510e-02, -2.21278369e-01, -9.77645740e-02,\n",
       "          2.66571671e-01,  8.79935324e-02,  1.94526657e-01,\n",
       "         -8.75640288e-02, -1.19001038e-01, -2.94631928e-01,\n",
       "         -2.84798384e-01,  1.48971364e-01],\n",
       "        [-5.90739548e-02, -3.33091587e-01, -1.02373928e-01,\n",
       "         -1.52920648e-01,  2.04528600e-01,  2.55822837e-02,\n",
       "          3.30680907e-02, -1.51653886e-01,  2.57702798e-01,\n",
       "          2.87747473e-01, -2.15052262e-01, -1.10969201e-01,\n",
       "          1.16554320e-01,  4.37631905e-02, -3.23052227e-01,\n",
       "         -6.65188432e-02, -9.76931155e-02, -5.07067144e-02,\n",
       "         -3.35226744e-01, -3.51369679e-01, -3.30073714e-01,\n",
       "          2.62060851e-01, -1.81114867e-01, -3.53863835e-03,\n",
       "         -2.73111314e-01, -1.37251288e-01,  2.37647206e-01,\n",
       "         -7.05212951e-02,  2.74020761e-01, -2.49541700e-01,\n",
       "         -3.24006915e-01,  7.72683322e-02],\n",
       "        [ 1.05938166e-01, -3.26712787e-01,  1.01643898e-01,\n",
       "          1.28540039e-01,  1.68181330e-01,  5.22022665e-01,\n",
       "         -2.35491633e-01, -1.21241733e-01, -4.77578580e-01,\n",
       "         -4.04115543e-02,  1.50403202e-01,  2.20864117e-01,\n",
       "          1.03941269e-01,  2.35786662e-01,  2.45943129e-01,\n",
       "         -4.16170627e-01,  1.30483031e-01, -3.40465635e-01,\n",
       "         -1.53614700e-01,  1.19543642e-01,  3.18194479e-01,\n",
       "         -2.41808236e-01,  1.26271278e-01, -1.73414066e-01,\n",
       "         -1.49322569e-01,  2.14499444e-01, -2.69330591e-01,\n",
       "         -2.32383311e-01,  1.50472075e-01,  2.26553291e-01,\n",
       "         -1.29073113e-01, -3.06736767e-01],\n",
       "        [ 2.92643160e-01, -3.49054337e-01, -1.49793401e-01,\n",
       "         -3.25048298e-01,  2.79790431e-01,  1.48249701e-01,\n",
       "         -2.28562683e-01,  2.01503649e-01, -6.70562685e-03,\n",
       "         -2.59480834e-01,  4.65579927e-01,  2.64803529e-01,\n",
       "         -4.76795077e-01, -2.37791508e-01,  2.85252240e-02,\n",
       "         -3.93407255e-01, -2.94572055e-01, -3.28044623e-01,\n",
       "         -4.51419890e-01,  3.17666203e-01, -1.91073909e-01,\n",
       "         -4.60447371e-01, -2.26835012e-01, -3.21186990e-01,\n",
       "          2.73598671e-01,  2.31395006e-01,  1.95209533e-01,\n",
       "          1.39271557e-01, -7.36834705e-02, -7.82203674e-03,\n",
       "          2.44690180e-02, -1.16212942e-01],\n",
       "        [ 3.46126884e-01,  2.61965692e-01,  2.43210196e-01,\n",
       "         -3.28589648e-01,  5.61048687e-02,  4.40728366e-01,\n",
       "          2.81010419e-01,  9.63950977e-02, -3.07690173e-01,\n",
       "          6.73234537e-02,  3.22993845e-01,  4.06029187e-02,\n",
       "          1.94986746e-01, -2.69396603e-01,  1.33664727e-01,\n",
       "         -2.95534343e-01, -1.95431113e-01,  2.42740646e-01,\n",
       "         -2.58940339e-01, -2.26833493e-01,  2.07602978e-04,\n",
       "          5.24619594e-02, -7.35054612e-02, -5.07724844e-02,\n",
       "          5.22136152e-01,  2.05171898e-01,  2.24367619e-01,\n",
       "         -6.86993897e-02,  3.32646310e-01, -1.36217773e-01,\n",
       "         -1.76905826e-01, -1.09743394e-01],\n",
       "        [ 2.69052178e-01, -3.33513111e-01,  5.57081103e-02,\n",
       "          2.70885617e-01,  2.62313217e-01,  5.19648194e-01,\n",
       "         -1.42542079e-01, -2.47020349e-01, -3.43990624e-01,\n",
       "         -3.17122400e-01,  5.81318855e-01,  3.65467250e-01,\n",
       "         -4.82159033e-02,  1.73800677e-01,  4.82233047e-01,\n",
       "         -3.45781475e-01, -9.23509821e-02,  2.38935813e-01,\n",
       "         -1.53218612e-01, -8.08924437e-03,  2.26400584e-01,\n",
       "         -2.90153027e-01, -2.47142032e-01, -4.09618050e-01,\n",
       "          2.68921107e-01,  3.27110589e-01, -1.09823411e-02,\n",
       "         -1.23628028e-01,  3.79327387e-01, -7.30641782e-02,\n",
       "         -2.53651798e-01, -4.63543683e-02],\n",
       "        [ 3.26548070e-01, -1.29773021e-01, -2.16224324e-02,\n",
       "          2.07718909e-02, -3.01217705e-01,  2.42639780e-01,\n",
       "          3.75568867e-02, -1.85326323e-01, -6.08040579e-02,\n",
       "          3.71905230e-02,  3.98335001e-03, -5.94219519e-03,\n",
       "         -5.82188740e-02,  1.50225252e-01,  5.65919876e-01,\n",
       "          1.83832929e-01,  1.47845209e-01, -3.96103188e-02,\n",
       "         -3.30281287e-01,  1.41913325e-01, -3.08513224e-01,\n",
       "         -7.99515918e-02,  4.61626053e-02, -2.15356082e-01,\n",
       "          1.73708901e-01,  5.18422663e-01, -1.88165039e-01,\n",
       "         -2.59659588e-01,  4.52625275e-01,  4.32739258e-02,\n",
       "         -2.62582600e-01, -6.77131265e-02],\n",
       "        [ 8.31564963e-02, -1.03205830e-01,  3.18378061e-01,\n",
       "         -2.29184031e-01, -3.67530584e-02,  6.29779994e-02,\n",
       "          7.60436058e-02, -3.14479202e-01, -2.56699622e-02,\n",
       "          1.50684267e-01,  2.31924266e-01,  4.33452427e-02,\n",
       "         -1.00156516e-01, -1.25151858e-01,  1.48848444e-01,\n",
       "         -2.56626606e-01, -2.08762288e-03, -1.34268984e-01,\n",
       "          3.02494764e-02, -2.29487807e-01, -9.68790054e-02,\n",
       "         -1.95112929e-01,  1.76016420e-01,  9.30722952e-02,\n",
       "          2.65721530e-01, -6.60689771e-02,  2.95827657e-01,\n",
       "         -1.81509957e-01,  1.13238543e-01,  2.02053279e-01,\n",
       "          1.48897737e-01,  6.36626482e-02],\n",
       "        [ 1.16840303e-02,  2.24496096e-01, -1.36137858e-01,\n",
       "         -2.31878459e-02, -4.09401953e-02, -1.53761148e-01,\n",
       "          1.04457766e-01,  3.38761419e-01,  3.50707173e-02,\n",
       "         -1.67276546e-01,  2.11858898e-01, -3.26454401e-01,\n",
       "         -4.54570651e-02, -6.53729737e-02,  3.45681459e-01,\n",
       "         -6.87342584e-02,  4.90817428e-03, -1.95786014e-01,\n",
       "          3.44287246e-01,  3.24796826e-01, -7.32976198e-03,\n",
       "         -1.68939739e-01,  1.09654635e-01,  1.72645718e-01,\n",
       "          4.34922576e-02,  3.00853550e-02,  1.79352969e-01,\n",
       "          2.78063387e-01, -2.99406558e-01, -7.77515769e-02,\n",
       "          2.09321409e-01,  1.10417992e-01],\n",
       "        [-4.85176966e-02, -1.01323642e-01,  8.26400071e-02,\n",
       "         -2.10304081e-01, -1.89887390e-01,  1.88688055e-01,\n",
       "          1.54334098e-01,  1.26027599e-01, -4.08149421e-01,\n",
       "         -6.67344555e-02,  3.21477987e-02,  3.86442184e-01,\n",
       "         -3.65532398e-01, -2.06761241e-01,  4.22041386e-01,\n",
       "         -3.44895363e-01, -8.57017189e-02, -2.02552691e-01,\n",
       "         -1.14818871e-01, -3.17492634e-01,  1.45133018e-01,\n",
       "         -2.60282815e-01,  2.13513643e-01, -3.92224565e-02,\n",
       "          2.94133216e-01, -2.72699352e-02, -3.20022285e-01,\n",
       "         -1.01252891e-01,  4.55868006e-01,  2.85978526e-01,\n",
       "          1.55857503e-02,  1.65918469e-02],\n",
       "        [ 3.19718152e-01,  2.81722277e-01,  1.30212933e-01,\n",
       "          3.28438908e-01, -1.43047079e-01,  4.10903990e-02,\n",
       "          2.36604065e-01, -3.04083765e-01,  1.39165610e-01,\n",
       "          6.19969070e-02,  3.24735671e-01, -5.54997325e-02,\n",
       "         -2.05436379e-01, -7.16805756e-02, -2.25772575e-01,\n",
       "          1.74418062e-01,  2.54181236e-01,  1.88844830e-01,\n",
       "         -1.31714627e-01, -2.61498392e-02, -8.52612257e-02,\n",
       "          4.27764654e-03, -3.12012255e-01, -2.93898731e-01,\n",
       "          3.17455232e-02,  3.16679627e-01, -3.39731246e-01,\n",
       "          9.42050219e-02, -6.89428151e-02, -2.26486877e-01,\n",
       "          1.11195594e-01, -2.99943984e-02],\n",
       "        [-5.84700368e-02,  3.62780303e-01,  2.79969215e-01,\n",
       "         -2.11884677e-01,  1.23227090e-01, -3.96231681e-01,\n",
       "         -9.30550992e-02,  3.60701740e-01,  8.03759843e-02,\n",
       "          1.17245816e-01, -4.61592227e-01, -5.09671450e-01,\n",
       "          5.62935472e-01,  2.10637793e-01, -1.05351722e-02,\n",
       "          3.40393007e-01,  2.57490069e-01, -3.59823316e-01,\n",
       "          5.15051246e-01, -2.09685877e-01,  4.86004353e-03,\n",
       "          4.17100489e-01, -1.31759733e-01,  5.68955421e-01,\n",
       "         -5.75983286e-01, -2.94876903e-01,  9.97498259e-02,\n",
       "         -1.53831001e-02, -6.17356181e-01, -8.80835354e-02,\n",
       "         -1.73570752e-01, -7.61822537e-02],\n",
       "        [ 2.44777389e-02,  3.70628685e-02, -1.04260229e-01,\n",
       "         -3.60503793e-02, -6.99072182e-02, -4.87207100e-02,\n",
       "         -1.25037134e-02,  1.07283853e-01,  3.77534449e-01,\n",
       "         -1.04928408e-02,  1.06768928e-01,  6.90216050e-02,\n",
       "          3.63534510e-01,  1.65799752e-01,  4.56762612e-02,\n",
       "          2.09430113e-01, -1.58231616e-01, -4.51762602e-02,\n",
       "          1.39831409e-01, -2.47142032e-01, -2.09841743e-01,\n",
       "          2.36487240e-01, -2.55821496e-01,  1.96684152e-01,\n",
       "          1.79998368e-01,  8.25764909e-02,  1.38760999e-01,\n",
       "          2.94580907e-01, -1.19281150e-01, -1.42877564e-01,\n",
       "          7.97206163e-03, -3.41861218e-01],\n",
       "        [-1.46446535e-02,  1.41681284e-01, -4.39331029e-03,\n",
       "         -2.70222247e-01, -1.46692693e-01,  4.33965147e-01,\n",
       "         -2.84266174e-02,  2.02657297e-01,  1.88828602e-01,\n",
       "          1.42147511e-01,  3.58255744e-01,  1.76167563e-01,\n",
       "         -1.36712790e-01, -1.38086513e-01,  2.48263687e-01,\n",
       "          3.09891433e-01, -2.59869426e-01,  1.44351482e-01,\n",
       "          3.00178379e-01, -4.11820114e-02,  9.69564617e-02,\n",
       "          2.34408349e-01, -3.96719873e-02,  1.97409630e-01,\n",
       "          2.30072528e-01, -5.42326197e-02, -3.40450436e-01,\n",
       "         -5.45207076e-02,  4.23134238e-01, -2.61901438e-01,\n",
       "         -3.04873586e-02,  2.47491017e-01],\n",
       "        [ 4.74907696e-01, -1.61196396e-01, -2.52889931e-01,\n",
       "          3.11395437e-01, -1.94929257e-01,  7.06152841e-02,\n",
       "         -3.28462183e-01, -2.58993208e-01, -2.15100974e-01,\n",
       "         -1.57122105e-01,  1.17041089e-01,  4.74106491e-01,\n",
       "         -4.80152071e-01, -3.35687946e-04,  5.80193102e-01,\n",
       "          1.64432645e-01,  8.79283622e-02, -2.14525551e-01,\n",
       "         -5.08582704e-02, -7.51277804e-02,  9.21628475e-02,\n",
       "          4.60458361e-02, -1.68845758e-01, -3.06910336e-01,\n",
       "          4.60410804e-01,  3.61219287e-01, -2.34994382e-01,\n",
       "          1.75526187e-01,  4.65570062e-01, -2.05657899e-01,\n",
       "         -1.30054474e-01,  1.59230411e-01],\n",
       "        [ 2.71600753e-01, -2.30832130e-01, -6.34938180e-02,\n",
       "         -9.67013836e-02,  2.40660340e-01,  9.27878022e-02,\n",
       "         -3.27477127e-01,  1.78805143e-01,  2.24940509e-01,\n",
       "         -2.37773046e-01, -1.23354465e-01,  2.11197883e-01,\n",
       "          3.12064588e-02, -7.52310157e-02, -1.94880784e-01,\n",
       "          3.50694984e-01,  3.10826570e-01, -1.25900298e-01,\n",
       "          2.36161619e-01,  2.32888490e-01,  3.14821869e-01,\n",
       "          3.43794674e-01, -2.92302966e-01,  2.51306325e-01,\n",
       "          2.22158879e-01, -2.47634649e-02,  1.34570748e-01,\n",
       "          1.52866691e-01, -3.05934787e-01,  2.69659311e-01,\n",
       "         -7.20720291e-02,  3.55966389e-02]], dtype=float32),\n",
       " array([-0.09517214,  0.17212106, -0.0208168 ,  0.        ,  0.        ,\n",
       "        -0.09928966,  0.        ,  0.11889972,  0.1759117 , -0.03201467,\n",
       "        -0.10404574, -0.07426912,  0.20278047, -0.04387021, -0.12326527,\n",
       "         0.22438864,  0.24690542, -0.02522853,  0.1852436 ,  0.        ,\n",
       "         0.        ,  0.13811609,  0.        ,  0.21839136, -0.09932662,\n",
       "        -0.0635637 , -0.00425205,  0.06056022, -0.0860934 ,  0.        ,\n",
       "         0.        , -0.0107213 ], dtype=float32),\n",
       " array([[-0.37840992,  0.48857394],\n",
       "        [ 0.21822858, -0.6210134 ],\n",
       "        [-0.3168379 , -0.1912696 ],\n",
       "        [-0.040941  , -0.36016148],\n",
       "        [ 0.13452414,  0.35884473],\n",
       "        [-0.45289278,  0.5076992 ],\n",
       "        [-0.2969195 ,  0.15131512],\n",
       "        [ 0.28566206, -0.37264657],\n",
       "        [ 0.63627285, -0.52189046],\n",
       "        [-0.06960855,  0.18266287],\n",
       "        [-0.49843997,  0.44573087],\n",
       "        [-0.61609936,  0.25282234],\n",
       "        [ 0.3548428 , -0.7102386 ],\n",
       "        [-0.14046298,  0.2304843 ],\n",
       "        [-0.00673085,  0.4997711 ],\n",
       "        [ 0.6791166 ,  0.00089826],\n",
       "        [ 0.11006181, -0.68843514],\n",
       "        [-0.35145822,  0.10540374],\n",
       "        [ 0.5970828 , -0.6245345 ],\n",
       "        [-0.40624258, -0.05146047],\n",
       "        [-0.33973593, -0.4196683 ],\n",
       "        [ 0.4650563 , -0.5425987 ],\n",
       "        [-0.25669372, -0.24575588],\n",
       "        [ 0.4411417 , -0.7712136 ],\n",
       "        [-0.3044866 ,  0.5183218 ],\n",
       "        [-0.6306647 ,  0.5084658 ],\n",
       "        [-0.22152734,  0.15654932],\n",
       "        [ 0.28976166, -0.39836046],\n",
       "        [-0.2636917 ,  0.34152484],\n",
       "        [-0.3849796 , -0.31207708],\n",
       "        [ 0.33344814,  0.18537536],\n",
       "        [-0.2899646 ,  0.38863108]], dtype=float32),\n",
       " array([ 0.1219822, -0.1219822], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x7fcdd8275160>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only need to save the architecture of a model, and not its weights or its training configuration, you can use the following function to save the architecure only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as JSON\n",
    "json_string = model.to_json()\n",
    "\n",
    "#save as YAML\n",
    "# yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"config\": {\"layers\": [{\"config\": {\"use_bias\": true, \"activation\": \"relu\", \"kernel_initializer\": {\"config\": {\"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"scale\": 1.0, \"seed\": null}, \"class_name\": \"VarianceScaling\"}, \"dtype\": \"float32\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"name\": \"dense_1\", \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"bias_constraint\": null, \"bias_initializer\": {\"config\": {}, \"class_name\": \"Zeros\"}, \"units\": 16, \"kernel_constraint\": null}, \"class_name\": \"Dense\"}, {\"config\": {\"use_bias\": true, \"activation\": \"relu\", \"kernel_initializer\": {\"config\": {\"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"scale\": 1.0, \"seed\": null}, \"class_name\": \"VarianceScaling\"}, \"trainable\": true, \"name\": \"dense_2\", \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"bias_constraint\": null, \"bias_initializer\": {\"config\": {}, \"class_name\": \"Zeros\"}, \"units\": 32, \"kernel_constraint\": null}, \"class_name\": \"Dense\"}, {\"config\": {\"use_bias\": true, \"activation\": \"softmax\", \"kernel_initializer\": {\"config\": {\"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"scale\": 1.0, \"seed\": null}, \"class_name\": \"VarianceScaling\"}, \"trainable\": true, \"name\": \"dense_3\", \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"bias_constraint\": null, \"bias_initializer\": {\"config\": {}, \"class_name\": \"Zeros\"}, \"units\": 2, \"kernel_constraint\": null}, \"class_name\": \"Dense\"}], \"name\": \"sequential_1\"}, \"keras_version\": \"2.2.4\", \"backend\": \"tensorflow\", \"class_name\": \"Sequential\"}'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reconstruction from JSON:\n",
    "from keras.models import model_from_json\n",
    "model_architecture = model_from_json(json_string)\n",
    "\n",
    "# model reconstruction from YAML:\n",
    "# from keras.models import model_from_yaml\n",
    "# model= model_from_yaml(yaml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_architecture.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. model.save_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only need to save the weights of a model, you can use the following function to save the weights only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
